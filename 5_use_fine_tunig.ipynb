{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 파인 튜닝을 위한 데이터 확보\n",
    "- 1_web_crawl.ipynb에서 얻었던 token.txt를 KoGPT2의 fine tuning을 해 학습시켜보았다. 그리고 이를 불러와 학습에 활용해보았다.\n",
    "\n",
    "\n",
    "아직 실행 안했고 코드만 쳐둠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gluonnlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15508/3498476527.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#라이브러리 import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgluonnlp\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnlp\u001b[0m \u001b[1;31m#이거 아직 설치 안함pip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgluonnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSentencepieceTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTFGPT2LMHeadModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gluonnlp'"
     ]
    }
   ],
   "source": [
    "#라이브러리 import\n",
    "import gluonnlp as nlp #이거 아직 설치 안함pip\n",
    "from gluonnlp.data import SentencepieceTokenizer\n",
    "from transformers import TFGPT2LMHeadModel\n",
    "import Tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 생성 방식 따라 디렉토리 경로 입력하는 클래스\n",
    "class GPT2Model(tf.keras.Model):\n",
    "    def __init__(self, dir_path):\n",
    "        super(GPT2Model, self).__init__()\n",
    "        self.gpt2 = TFGPT2LMHeadModel.from_pretrained(dir_path)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.gpt2(inputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n",
      "'unzip'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n"
     ]
    }
   ],
   "source": [
    "#파라미터 불러오는 명령어\n",
    "!wget https://www.dropbox.com/s/nzfa9xpzm4edp6o/gpt_ckpt.zip -O gpt_ckpt.zip\n",
    "!unzip -o gpt_ckpt.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GPT2Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15508/981145623.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mBASE_MODEL_PATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./gpt_ckpt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgpt_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGPT2Model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBASE_MODEL_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'GPT2Model' is not defined"
     ]
    }
   ],
   "source": [
    "BASE_MODEL_PATH = './gpt_ckpt'\n",
    "gpt_model = GPT2Model(BASE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#토크나이저\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 10\n",
    "MAX_LEN = 30\n",
    "TOKENIZER_PATH = '.gpt_ckpt/gpt2_kor_tokenizer.spiece'\n",
    "\n",
    "tokenizer = SentencepieceTokenizer(TOKENIZER_PATH)\n",
    "vocab = nlp.vocab.BERTVocab.from_sentencepiece(TOKENIZER_PATH, mask_token=None, spe_token=None, cls_token=None, unknown_token='<unk>', padding_token='<pad>', bos_token='<s>', eos_token='</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#토크나이저 & 사전 학습 모델 통해 문장 만들기 함수\n",
    "def tf_top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-99999):\n",
    "    _logits = logits.numpy()\n",
    "    top_k = min(top_k, logits.shape[-1])\n",
    "    if top_k > 0:\n",
    "        indicees_to_remove = logits < tf.math.top_k(logits, top_k)[0][...,-1,None]\n",
    "        _logits[indicees_to_remove] = filter_value\n",
    "    \n",
    "    if top_p > 0.0:\n",
    "        sorted_logits = tf.sort(logits, direction='DESCENDING')\n",
    "        sorted_indices = tf.argsort(logits, direction='DESCENDING')\n",
    "        cumulative_probs = tf.math.cunsum(tf.nn.softmax(sorted_logits, axis=-1), axis =-1)\n",
    "\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        sorted_indices_to_remove = tf.concat([[False], sorted_indices_to_remove[..., :-1]], axis=0)\n",
    "        indicees_to_remove = sorted_indices[sorted_indices_to_remove].numpy().tolist()\n",
    "\n",
    "        _logits[indicees_to_remove] = filter_value\n",
    "    return tf.constant([_logits])\n",
    "\n",
    "def generate_sent(seed_word, model, max_step=100, greedy=False, top_k=0, top_p=0.):\n",
    "    sent = seed_word\n",
    "    toked = tokenizer(sent)\n",
    "\n",
    "    for _ in range(max_step):\n",
    "        input_ids = tf.constant([vocab[vocab.bos_token],] + vocab[toked])[None, :]\n",
    "        outputs = model(input_ids)[:, -1, :]\n",
    "        if greedy:\n",
    "            gen = vocab.to_tokens(tf.argmax(outputs, axis=-1).numpy().tolist()[0])\n",
    "        else:\n",
    "            output_logit = tf_top_k_top_p_filtering(outputs[0], top_k=top_k, top_p=top_p)\n",
    "            gen = vocab.to_tokens(tf.random.categorical(output_logit, 1).numpy().tolist()[0])[0]\n",
    "        if gen == '</s>':\n",
    "            break\n",
    "        sent += gen.replace('_', ' ')\n",
    "        toked = tokenizer(sent)\n",
    "    \n",
    "    return sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#가사 집어넣기\n",
    "DATA_IN_PATH = './data_in/KOR' #이 부분 바꿔야 할 가능성 아주 농후함, 파일 주소라서 없어도 될지도?\n",
    "TRAIN_DATA_FILE = 'data.txt'\n",
    "\n",
    "sents = [s[:-1] for s in open(DATA_IN_PATH + TRAIN_DATA_FILE).readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#토크나이저에 넣기\n",
    "input_data = []\n",
    "output_data = []\n",
    "\n",
    "for s in sents:\n",
    "    tokens = [vocab[vocab.bos_token],] + vocab[tokenizer(s)] + [vocab[vocab.eos_token],]\n",
    "    input_data.append(tokens[:-1])\n",
    "    output_data.append(tokens[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#입출력 구성\n",
    "input_data = pad_sequences(input_data, MAX_LEN, value=vocab[vocab.padding_token])\n",
    "output_data = pad_sequences(output_data, MAX_LEN, value=vocab[vocab.padding_token])\n",
    "\n",
    "input_data = np.array(input_data, dtype=np.int64)\n",
    "output_data = np.array(output_data, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#손실함수 & 정확도 측정 설정\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, vocab[vocab.padding_token]))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, vocab[vocab.padding_token]))\n",
    "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=1)\n",
    "    pred *= mask\n",
    "    acc = train_accuracy(real, pred)\n",
    "\n",
    "    return tf.reduce_mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 컴파일\n",
    "gpt_model.compile(loss=loss_function, optimizer=tf.keras.optimizers.Adam(1e-4), metrics=[accuracy_function])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 실행\n",
    "history = gpt_model.fit(input_data, output_data, batch_size = BATCH_SIZE, epochs = NUM_EPOCHS, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#저장\n",
    "DATA_OUT_PATH = './data_out'\n",
    "model_name = 'tf2_gpt2_finetuned_model'\n",
    "save_path = os.path.join(DATA_OUT_PATH, model_name)\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "gpt_model.gpt2.save_pretrained(save_path)\n",
    "\n",
    "loaded_gpt_model = GPT2Model(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#결과 확인\n",
    "print(generate_sent('어떠한', gpt_model, greedy=True))\n",
    "print('-'*16)\n",
    "print(generate_sent('어떠한', gpt_model, greedy=False))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9efe4e546d06fb70330cc2ef1b74164090806f6e5821eec9578b2609166785fd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('section4project': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
